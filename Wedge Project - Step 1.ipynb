{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bf0d7e",
   "metadata": {},
   "source": [
    "# The Wedge\n",
    "\n",
    "## Task 1: Building a Transaction Database in Google Big Query!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fc073",
   "metadata": {},
   "source": [
    "## Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f939f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import re\n",
    "import datetime \n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import janitor\n",
    "\n",
    "from zipfile import ZipFile # usually you'd do all these imports at the beginning\n",
    "\n",
    "# Do our imports for the code\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95514695",
   "metadata": {},
   "source": [
    "## Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f2fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Small File Sample\n",
    "# zip_file_name = \"WedgeZipOfZips_Small.zip\"\n",
    "\n",
    "## Full data Set\n",
    "zip_file_name = \"WedgeZipOfZips.zip\"\n",
    "\n",
    "# Clean data Set\n",
    "# zip_file_name = \"WedgeFiles_Clean.zip\"\n",
    "\n",
    "# Small Clean Data Set\n",
    "# zip_file_name = \"WedgeZipOfZips_Small_Clean.zip\"\n",
    "\n",
    "# Working Directory included in .gitignore\n",
    "# working_directory = \"/media/psf/Home/Repos/BMKT670.V60-72020-Fall2022-Wedge-Project/eggs/\"\n",
    "working_directory = \"/home/blackvwgolf95/BMKT670.V60-72020-Fall2022-Wedge-Project/eggs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d6932",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578cf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zf):\n",
    "    # printing what's in the zip file.  \n",
    "    # zf.printdir() \n",
    "\n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    # pick a folder name already in .gitignore\n",
    "    \n",
    "    # Instead of always extracting ALL, check if file exists first\n",
    "    # zf.extractall(working_directory) \n",
    "    \n",
    "    zipped_files = zf.namelist()\n",
    "    # display_zip_contents(zipped_files)\n",
    "    \n",
    "    # Only extract files if they don't exist\n",
    "    for file_name in zipped_files :\n",
    "        \n",
    "        # Ignore .DS_Store hidden files\n",
    "        if(file_name.endswith( '.DS_Store' )):\n",
    "            continue\n",
    "            \n",
    "        # Ignore __MACOSX hidden files\n",
    "        if(file_name.startswith( '__' )):\n",
    "            continue\n",
    "        \n",
    "        # Ignore folders\n",
    "        if(file_name.endswith( '/' )):\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(working_directory + file_name) :\n",
    "            print(\"File Exists, skipping\")\n",
    "            print(file_name)\n",
    "        else :\n",
    "            print(\"Need to Extract\")\n",
    "            print(file_name)\n",
    "            zf.extract(file_name, working_directory) \n",
    "        \n",
    "        zip_files.append(file_name)\n",
    "        \n",
    "def extract_single_zip(zf):\n",
    "    zipped_files = zf.namelist()\n",
    "    # display_zip_contents(zipped_files)\n",
    "    \n",
    "    # Only extract files if they don't exist\n",
    "    for file_name in zipped_files :\n",
    "        \n",
    "        # Ignore .DS_Store hidden files\n",
    "        if(file_name.endswith( '.DS_Store' )):\n",
    "            continue\n",
    "            \n",
    "        # Ignore __MACOSX hidden files\n",
    "        if(file_name.startswith( '__' )):\n",
    "            continue\n",
    "        \n",
    "        # Ignore folders\n",
    "        if(file_name.endswith( '/' )):\n",
    "            continue\n",
    "        \n",
    "        if os.path.exists(working_directory + file_name) :\n",
    "            print(\"File Exists, skipping\")\n",
    "            print(file_name)\n",
    "        else :\n",
    "            print(\"Need to Extract\")\n",
    "            print(file_name)\n",
    "            zf.extract(file_name, working_directory) \n",
    "        \n",
    "        data_files.append(file_name)\n",
    "\n",
    "\n",
    "def display_zip_contents(zipped_files):\n",
    "    for file_name in zipped_files :\n",
    "        # Ignore __MACOSX hidden files\n",
    "        if(file_name.startswith( '__' )):\n",
    "            continue\n",
    "        # Ignore .DS_Store hidden files\n",
    "        if(file_name.endswith( '.DS_Store' )):\n",
    "            continue\n",
    "        # Ignore folders\n",
    "        if(file_name.endswith( '/' )):\n",
    "            continue\n",
    "\n",
    "        print(\"File: \", file_name,\" Size:\", os.path.getsize(working_directory+file_name))\n",
    "\n",
    "def display_file_contents(files):\n",
    "    for file_name in files :\n",
    "        # Ignore __MACOSX hidden files\n",
    "        if(file_name.startswith( '__' )):\n",
    "            continue\n",
    "        # Ignore .DS_Store hidden files\n",
    "        if(file_name.endswith( '.DS_Store' )):\n",
    "            continue\n",
    "        # Ignore folders\n",
    "        if(file_name.endswith( '/' )):\n",
    "            continue\n",
    "\n",
    "        print(\"File: \", file_name,\" Size:\", os.path.getsize(working_directory+file_name))\n",
    "\n",
    "def get_delimiter(file_name) :\n",
    "    # Get separator\n",
    "    input_file = open(working_directory+file_name,'r')\n",
    "    # input_file = io.TextIOWrapper(input_file,encoding=\"utf-8\")\n",
    "            \n",
    "    dialect = csv.Sniffer().sniff(sample=input_file.readline(),\n",
    "                                  delimiters=[\",\",\";\",\"\\t\"])\n",
    "    delimiter = dialect.delimiter\n",
    "    # delimiters[file_name] = dialect.delimiter\n",
    "\n",
    "    #     print(\" \".join([\"It looks like\",\n",
    "    #                    file_name,\n",
    "    #                    \"has delimiter\",\n",
    "    #                    dialect.delimiter,\n",
    "    #                    \".\"]))\n",
    "    input_file.close() # tidy up\n",
    "    return delimiter\n",
    "\n",
    "def get_header(file_name) :\n",
    "    \n",
    "    with open(working_directory+file_name) as f:\n",
    "        first_line = f.readline()\n",
    "        # print(first_line)\n",
    "        if first_line.startswith('datetime') :\n",
    "            return 0\n",
    "        if first_line.startswith('\"datetime\"') :\n",
    "            return 0\n",
    "        if first_line.startswith(\"'datetime'\") :\n",
    "            return 0\n",
    "        else :\n",
    "            return None\n",
    "\n",
    "def upload_data(data):\n",
    "    # https://stackoverflow.com/a/24083253\n",
    "    grouped = data.groupby(pd.Grouper(freq='M'))\n",
    "    for name, group in grouped:\n",
    "\n",
    "        # Construct table name from index\n",
    "        # table_name = \"dram_items_\"+reformat_date(name.strftime('%Y-%m-%d'))\n",
    "\n",
    "        # 3. For each month in the file, subset the data to that month and \n",
    "        #    upload the data to a table called `dram_items_YYYYMM01`. \n",
    "        # table_id = \".\".join([gbq_proj_id,dataset_id,table_name])\n",
    "        # print(table_id)\n",
    "        # pandas_gbq.to_gbq(item_lu, table_id, project_id=gbq_proj_id,if_exists=\"replace\") # let's discuss this last bit\n",
    "        print(\"Data Uploaded!\")\n",
    "        \n",
    "def cleanup_data(data): \n",
    "    # Clean the names with the janitor package.\n",
    "    data = janitor.clean_names(data)\n",
    "\n",
    "#     for column in ( 'gross_sales', 'discounts', 'net_sales', 'tax' ):\n",
    "#         # Convert the fields that have dollar signs (such as `gross_sales`) into numeric data. Watch out for dollar signs and commas.\n",
    "#         data[column] = ( data[column]\n",
    "#                            .str.replace(\"$\", '', regex=False)\n",
    "#                            .str.replace(\",\", '', regex=False)\n",
    "#                            .astype(float) )\n",
    "\n",
    "    # Change the type of the column `modifiers_applied` to string.\n",
    "#     data['modifiers_applied'] = data['modifiers_applied'].astype(str)\n",
    "\n",
    "    # Replace the `sku` column with a column of empty strings. \n",
    "#     data['sku'] = ''\n",
    "\n",
    "    # print( item_lu.head() )\n",
    "#     data.index = pd.to_datetime(data['date']) # ,format='%y-%m-%d'  \n",
    "    return data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43101f9d",
   "metadata": {},
   "source": [
    "## GBQ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4428fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These first two values will be different on your machine. \n",
    "# service_path = \"/Users/chandler/Dropbox/Teaching/\"\n",
    "# service_file = 'umt-msba-037daf11ee16.json' # change this to your authentication information  \n",
    "# gbq_proj_id = 'umt-msba' # change this to your project. \n",
    "# service_path = \"/media/psf/Home/Repos/\"\n",
    "service_path = \"/home/blackvwgolf95/\"\n",
    "service_file = 'bmkt670-fall2022-wedge-project-6ce4398b80e4.json' # change this to your authentication information  \n",
    "gbq_proj_id = 'bmkt670-fall2022-wedge-project' # change this to your project. \n",
    "dataset_id = 'wedgedataset'\n",
    "\n",
    "# And this should stay the same. \n",
    "private_key = service_path + service_file\n",
    "\n",
    "# Now we pass in our credentials so that Python has permission to access our project.\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# And finally we establish our connection\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)\n",
    "\n",
    "# for item in client.list_datasets() : \n",
    "#    print(item.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050d4f2",
   "metadata": {},
   "source": [
    "## Phase 1, Upload Clean Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6bfe9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all the files now...\n",
      "File Exists, skipping\n",
      "transArchive_201001_201003.zip\n",
      "File Exists, skipping\n",
      "transArchive_201004_201006.zip\n",
      "File Exists, skipping\n",
      "transArchive_201007_201009.zip\n",
      "File Exists, skipping\n",
      "transArchive_201010_201012.zip\n",
      "File Exists, skipping\n",
      "transArchive_201101_201103.zip\n",
      "File Exists, skipping\n",
      "transArchive_201104.zip\n",
      "File Exists, skipping\n",
      "transArchive_201105.zip\n",
      "File Exists, skipping\n",
      "transArchive_201106.zip\n",
      "File Exists, skipping\n",
      "transArchive_201107_201109.zip\n",
      "File Exists, skipping\n",
      "transArchive_201110_201112.zip\n",
      "File Exists, skipping\n",
      "transArchive_201201_201203.zip\n",
      "File Exists, skipping\n",
      "transArchive_201201_201203_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201204_201206.zip\n",
      "File Exists, skipping\n",
      "transArchive_201204_201206_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201207_201209.zip\n",
      "File Exists, skipping\n",
      "transArchive_201207_201209_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201210_201212.zip\n",
      "File Exists, skipping\n",
      "transArchive_201210_201212_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201301_201303.zip\n",
      "File Exists, skipping\n",
      "transArchive_201301_201303_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201304_201306.zip\n",
      "File Exists, skipping\n",
      "transArchive_201304_201306_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201307_201309.zip\n",
      "File Exists, skipping\n",
      "transArchive_201307_201309_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201310_201312.zip\n",
      "File Exists, skipping\n",
      "transArchive_201310_201312_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201401_201403.zip\n",
      "File Exists, skipping\n",
      "transArchive_201401_201403_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201404_201406.zip\n",
      "File Exists, skipping\n",
      "transArchive_201404_201406_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201407_201409.zip\n",
      "File Exists, skipping\n",
      "transArchive_201407_201409_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201410_201412.zip\n",
      "File Exists, skipping\n",
      "transArchive_201410_201412_inactive.zip\n",
      "File Exists, skipping\n",
      "transArchive_201501_201503.zip\n",
      "File Exists, skipping\n",
      "transArchive_201504_201506.zip\n",
      "File Exists, skipping\n",
      "transArchive_201507_201509.zip\n",
      "File Exists, skipping\n",
      "transArchive_201510.zip\n",
      "File Exists, skipping\n",
      "transArchive_201511.zip\n",
      "File Exists, skipping\n",
      "transArchive_201512.zip\n",
      "File Exists, skipping\n",
      "transArchive_201601.zip\n",
      "File Exists, skipping\n",
      "transArchive_201602.zip\n",
      "File Exists, skipping\n",
      "transArchive_201603.zip\n",
      "File Exists, skipping\n",
      "transArchive_201604.zip\n",
      "File Exists, skipping\n",
      "transArchive_201605.zip\n",
      "File Exists, skipping\n",
      "transArchive_201606.zip\n",
      "File Exists, skipping\n",
      "transArchive_201607.zip\n",
      "File Exists, skipping\n",
      "transArchive_201608.zip\n",
      "File Exists, skipping\n",
      "transArchive_201609.zip\n",
      "File Exists, skipping\n",
      "transArchive_201610.zip\n",
      "File Exists, skipping\n",
      "transArchive_201611.zip\n",
      "File Exists, skipping\n",
      "transArchive_201612.zip\n",
      "File Exists, skipping\n",
      "transArchive_201701.zip\n",
      "Done Extracting!\n",
      "Done building file list\n"
     ]
    }
   ],
   "source": [
    "# In this cell, do the following: \n",
    "\n",
    "# Master list of all data files\n",
    "zip_files = []\n",
    "\n",
    "with ZipFile( zip_file_name, 'r') as zf : \n",
    "    extract_zip(zf)\n",
    "    print('Done Extracting!')\n",
    "    \n",
    "\n",
    "print(\"Done building file list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943d5b50",
   "metadata": {},
   "source": [
    "## Verify ZIP Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70dac1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  transArchive_201001_201003.zip  Size: 99503110\n",
      "File:  transArchive_201004_201006.zip  Size: 105550247\n",
      "File:  transArchive_201007_201009.zip  Size: 99939988\n",
      "File:  transArchive_201010_201012.zip  Size: 101366220\n",
      "File:  transArchive_201101_201103.zip  Size: 100781163\n",
      "File:  transArchive_201104.zip  Size: 32868743\n",
      "File:  transArchive_201105.zip  Size: 32785831\n",
      "File:  transArchive_201106.zip  Size: 27652309\n",
      "File:  transArchive_201107_201109.zip  Size: 101917553\n",
      "File:  transArchive_201110_201112.zip  Size: 107752470\n",
      "File:  transArchive_201201_201203.zip  Size: 102376566\n",
      "File:  transArchive_201201_201203_inactive.zip  Size: 8652264\n",
      "File:  transArchive_201204_201206.zip  Size: 104625854\n",
      "File:  transArchive_201204_201206_inactive.zip  Size: 8318216\n",
      "File:  transArchive_201207_201209.zip  Size: 98925996\n",
      "File:  transArchive_201207_201209_inactive.zip  Size: 6652257\n",
      "File:  transArchive_201210_201212.zip  Size: 99601626\n",
      "File:  transArchive_201210_201212_inactive.zip  Size: 5771070\n",
      "File:  transArchive_201301_201303.zip  Size: 100283765\n",
      "File:  transArchive_201301_201303_inactive.zip  Size: 5287856\n",
      "File:  transArchive_201304_201306.zip  Size: 102925855\n",
      "File:  transArchive_201304_201306_inactive.zip  Size: 4821923\n",
      "File:  transArchive_201307_201309.zip  Size: 101441773\n",
      "File:  transArchive_201307_201309_inactive.zip  Size: 3635092\n",
      "File:  transArchive_201310_201312.zip  Size: 101068191\n",
      "File:  transArchive_201310_201312_inactive.zip  Size: 2816054\n",
      "File:  transArchive_201401_201403.zip  Size: 100327638\n",
      "File:  transArchive_201401_201403_inactive.zip  Size: 1861830\n",
      "File:  transArchive_201404_201406.zip  Size: 106949494\n",
      "File:  transArchive_201404_201406_inactive.zip  Size: 1698415\n",
      "File:  transArchive_201407_201409.zip  Size: 102612918\n",
      "File:  transArchive_201407_201409_inactive.zip  Size: 973997\n",
      "File:  transArchive_201410_201412.zip  Size: 100896529\n",
      "File:  transArchive_201410_201412_inactive.zip  Size: 272691\n",
      "File:  transArchive_201501_201503.zip  Size: 103865669\n",
      "File:  transArchive_201504_201506.zip  Size: 109102338\n",
      "File:  transArchive_201507_201509.zip  Size: 104396138\n",
      "File:  transArchive_201510.zip  Size: 33966643\n",
      "File:  transArchive_201511.zip  Size: 27390123\n",
      "File:  transArchive_201512.zip  Size: 26286758\n",
      "File:  transArchive_201601.zip  Size: 27123537\n",
      "File:  transArchive_201602.zip  Size: 24005493\n",
      "File:  transArchive_201603.zip  Size: 26125096\n",
      "File:  transArchive_201604.zip  Size: 25008899\n",
      "File:  transArchive_201605.zip  Size: 25115191\n",
      "File:  transArchive_201606.zip  Size: 22868009\n",
      "File:  transArchive_201607.zip  Size: 23123116\n",
      "File:  transArchive_201608.zip  Size: 22843936\n",
      "File:  transArchive_201609.zip  Size: 23216652\n",
      "File:  transArchive_201610.zip  Size: 24474870\n",
      "File:  transArchive_201611.zip  Size: 25044922\n",
      "File:  transArchive_201612.zip  Size: 25209315\n",
      "File:  transArchive_201701.zip  Size: 25523831\n"
     ]
    }
   ],
   "source": [
    "display_file_contents(zip_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aaf797",
   "metadata": {},
   "source": [
    "## Extract Inner Zips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c3d174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to Extract\n",
      "transArchive_201001_201003.csv\n",
      "Need to Extract\n",
      "transArchive_201004_201006.csv\n",
      "Need to Extract\n",
      "transArchive_201007_201009.csv\n",
      "Need to Extract\n",
      "transArchive_201010_201012.csv\n",
      "Need to Extract\n",
      "transArchive_201101_201103.csv\n",
      "Need to Extract\n",
      "transArchive_201104.csv\n",
      "Need to Extract\n",
      "transArchive_201105.csv\n",
      "Need to Extract\n",
      "transArchive_201106.csv\n",
      "Need to Extract\n",
      "transArchive_201107_201109.csv\n",
      "Need to Extract\n",
      "transArchive_201110_201112.csv\n",
      "Need to Extract\n",
      "transArchive_201201_201203.csv\n",
      "Need to Extract\n",
      "transArchive_201201_201203_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201204_201206.csv\n",
      "Need to Extract\n",
      "transArchive_201204_201206_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201207_201209.csv\n",
      "Need to Extract\n",
      "transArchive_201207_201209_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201210_201212.csv\n",
      "Need to Extract\n",
      "transArchive_201210_201212_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201301_201303.csv\n",
      "Need to Extract\n",
      "transArchive_201301_201303_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201304_201306.csv\n",
      "Need to Extract\n",
      "transArchive_201304_201306_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201307_201309.csv\n",
      "Need to Extract\n",
      "transArchive_201307_201309_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201310_201312.csv\n",
      "Need to Extract\n",
      "transArchive_201310_201312_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201401_201403.csv\n",
      "Need to Extract\n",
      "transArchive_201401_201403_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201404_201406.csv\n",
      "Need to Extract\n",
      "transArchive_201404_201406_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201407_201409.csv\n",
      "Need to Extract\n",
      "transArchive_201407_201409_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201410_201412.csv\n",
      "Need to Extract\n",
      "transArchive_201410_201412_inactive.csv\n",
      "Need to Extract\n",
      "transArchive_201501_201503.csv\n",
      "Need to Extract\n",
      "transArchive_201504_201506.csv\n",
      "Need to Extract\n",
      "transArchive_201507_201509.csv\n",
      "Need to Extract\n",
      "transArchive_201510.csv\n",
      "Need to Extract\n",
      "transArchive_201511.csv\n",
      "Need to Extract\n",
      "transArchive_201512.csv\n",
      "Need to Extract\n",
      "transArchive_201601.csv\n",
      "Need to Extract\n",
      "transArchive_201602.csv\n",
      "Need to Extract\n",
      "transArchive_201603.csv\n",
      "Need to Extract\n",
      "transArchive_201604.csv\n",
      "Need to Extract\n",
      "transArchive_201605.csv\n",
      "Need to Extract\n",
      "transArchive_201606.csv\n",
      "Need to Extract\n",
      "transArchive_201607.csv\n",
      "Need to Extract\n",
      "transArchive_201608.csv\n",
      "Need to Extract\n",
      "transArchive_201609.csv\n",
      "Need to Extract\n",
      "transArchive_201610.csv\n",
      "Need to Extract\n",
      "transArchive_201611.csv\n",
      "Need to Extract\n",
      "transArchive_201612.csv\n",
      "Need to Extract\n",
      "transArchive_201701.csv\n"
     ]
    }
   ],
   "source": [
    "data_files = []\n",
    "\n",
    "for inner_zip_file_name in zip_files :\n",
    "    # print(working_directory + inner_zip_file_name)\n",
    "    # Ignore folders\n",
    "    if not inner_zip_file_name.endswith( '.zip' ):\n",
    "        continue\n",
    "    with ZipFile( working_directory + inner_zip_file_name, 'r') as zf : \n",
    "        extract_single_zip(zf)\n",
    "#         extract_single_zips(zip_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a86bd",
   "metadata": {},
   "source": [
    "## Verify Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd5b8288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  transArchive_201001_201003.csv  Size: 872986330\n",
      "File:  transArchive_201004_201006.csv  Size: 924799264\n",
      "File:  transArchive_201007_201009.csv  Size: 870731849\n",
      "File:  transArchive_201010_201012.csv  Size: 871310253\n",
      "File:  transArchive_201101_201103.csv  Size: 864157752\n",
      "File:  transArchive_201104.csv  Size: 227905318\n",
      "File:  transArchive_201105.csv  Size: 228086734\n",
      "File:  transArchive_201106.csv  Size: 211641602\n",
      "File:  transArchive_201107_201109.csv  Size: 887540984\n",
      "File:  transArchive_201110_201112.csv  Size: 921964153\n",
      "File:  transArchive_201201_201203.csv  Size: 882675809\n",
      "File:  transArchive_201201_201203_inactive.csv  Size: 73077877\n",
      "File:  transArchive_201204_201206.csv  Size: 909110503\n",
      "File:  transArchive_201204_201206_inactive.csv  Size: 70658122\n",
      "File:  transArchive_201207_201209.csv  Size: 862091646\n",
      "File:  transArchive_201207_201209_inactive.csv  Size: 56592162\n",
      "File:  transArchive_201210_201212.csv  Size: 854750338\n",
      "File:  transArchive_201210_201212_inactive.csv  Size: 48461658\n",
      "File:  transArchive_201301_201303.csv  Size: 858519468\n",
      "File:  transArchive_201301_201303_inactive.csv  Size: 44235824\n",
      "File:  transArchive_201304_201306.csv  Size: 892669880\n",
      "File:  transArchive_201304_201306_inactive.csv  Size: 40879398\n",
      "File:  transArchive_201307_201309.csv  Size: 883011873\n",
      "File:  transArchive_201307_201309_inactive.csv  Size: 30929143\n",
      "File:  transArchive_201310_201312.csv  Size: 863763593\n",
      "File:  transArchive_201310_201312_inactive.csv  Size: 23516715\n",
      "File:  transArchive_201401_201403.csv  Size: 862428070\n",
      "File:  transArchive_201401_201403_inactive.csv  Size: 15638932\n",
      "File:  transArchive_201404_201406.csv  Size: 929314229\n",
      "File:  transArchive_201404_201406_inactive.csv  Size: 14523999\n",
      "File:  transArchive_201407_201409.csv  Size: 891328267\n",
      "File:  transArchive_201407_201409_inactive.csv  Size: 8342775\n",
      "File:  transArchive_201410_201412.csv  Size: 862974284\n",
      "File:  transArchive_201410_201412_inactive.csv  Size: 2343984\n",
      "File:  transArchive_201501_201503.csv  Size: 886497105\n",
      "File:  transArchive_201504_201506.csv  Size: 951790137\n",
      "File:  transArchive_201507_201509.csv  Size: 908770215\n",
      "File:  transArchive_201510.csv  Size: 292887498\n",
      "File:  transArchive_201511.csv  Size: 195312128\n",
      "File:  transArchive_201512.csv  Size: 177859742\n",
      "File:  transArchive_201601.csv  Size: 193028154\n",
      "File:  transArchive_201602.csv  Size: 171888915\n",
      "File:  transArchive_201603.csv  Size: 189014113\n",
      "File:  transArchive_201604.csv  Size: 181787557\n",
      "File:  transArchive_201605.csv  Size: 182765005\n",
      "File:  transArchive_201606.csv  Size: 167416548\n",
      "File:  transArchive_201607.csv  Size: 169550468\n",
      "File:  transArchive_201608.csv  Size: 166766297\n",
      "File:  transArchive_201609.csv  Size: 167575658\n",
      "File:  transArchive_201610.csv  Size: 176381340\n",
      "File:  transArchive_201611.csv  Size: 180569894\n",
      "File:  transArchive_201612.csv  Size: 179272312\n",
      "File:  transArchive_201701.csv  Size: 183364865\n"
     ]
    }
   ],
   "source": [
    "display_file_contents(data_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb9776",
   "metadata": {},
   "source": [
    "### Checking for and deleting previous tables\n",
    "\n",
    "We'll get all the tables in our Dram data set that match our pattern, then delete them. We do not want to accidentally delete the item lookup table that we put in this data set in class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffde1479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at transArchive_201001_201003\n",
      "She swiped right, we have a MATCH! transArchive_201001_201003\n",
      "She blocked us, all hope is lost transArchive_201001_201003.\n",
      "Looking at transArchive_201004_201006\n",
      "She swiped right, we have a MATCH! transArchive_201004_201006\n",
      "She blocked us, all hope is lost transArchive_201004_201006.\n",
      "Looking at transArchive_201007_201009\n",
      "She swiped right, we have a MATCH! transArchive_201007_201009\n",
      "She blocked us, all hope is lost transArchive_201007_201009.\n",
      "Looking at transArchive_201010_201012\n",
      "She swiped right, we have a MATCH! transArchive_201010_201012\n",
      "She blocked us, all hope is lost transArchive_201010_201012.\n",
      "Looking at transArchive_201101_201103\n",
      "She swiped right, we have a MATCH! transArchive_201101_201103\n",
      "She blocked us, all hope is lost transArchive_201101_201103.\n",
      "Looking at transArchive_201104\n",
      "She swiped right, we have a MATCH! transArchive_201104\n",
      "She blocked us, all hope is lost transArchive_201104.\n",
      "Looking at transArchive_201105\n",
      "She swiped right, we have a MATCH! transArchive_201105\n",
      "She blocked us, all hope is lost transArchive_201105.\n",
      "Looking at transArchive_201106\n",
      "She swiped right, we have a MATCH! transArchive_201106\n",
      "She blocked us, all hope is lost transArchive_201106.\n",
      "Looking at transArchive_201107_201109\n",
      "She swiped right, we have a MATCH! transArchive_201107_201109\n",
      "She blocked us, all hope is lost transArchive_201107_201109.\n",
      "Looking at transArchive_201110_201112\n",
      "She swiped right, we have a MATCH! transArchive_201110_201112\n",
      "She blocked us, all hope is lost transArchive_201110_201112.\n",
      "Looking at transArchive_201201_201203\n",
      "She swiped right, we have a MATCH! transArchive_201201_201203\n",
      "She blocked us, all hope is lost transArchive_201201_201203.\n",
      "Looking at transArchive_201201_201203_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201201_201203_inactive\n",
      "She blocked us, all hope is lost transArchive_201201_201203_inactive.\n",
      "Looking at transArchive_201204_201206\n",
      "She swiped right, we have a MATCH! transArchive_201204_201206\n",
      "She blocked us, all hope is lost transArchive_201204_201206.\n",
      "Looking at transArchive_201204_201206_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201204_201206_inactive\n",
      "She blocked us, all hope is lost transArchive_201204_201206_inactive.\n",
      "Looking at transArchive_201207_201209\n",
      "She swiped right, we have a MATCH! transArchive_201207_201209\n",
      "She blocked us, all hope is lost transArchive_201207_201209.\n",
      "Looking at transArchive_201207_201209_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201207_201209_inactive\n",
      "She blocked us, all hope is lost transArchive_201207_201209_inactive.\n",
      "Looking at transArchive_201210_201212\n",
      "She swiped right, we have a MATCH! transArchive_201210_201212\n",
      "She blocked us, all hope is lost transArchive_201210_201212.\n",
      "Looking at transArchive_201210_201212_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201210_201212_inactive\n",
      "She blocked us, all hope is lost transArchive_201210_201212_inactive.\n",
      "Looking at transArchive_201301_201303\n",
      "She swiped right, we have a MATCH! transArchive_201301_201303\n",
      "She blocked us, all hope is lost transArchive_201301_201303.\n",
      "Looking at transArchive_201301_201303_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201301_201303_inactive\n",
      "She blocked us, all hope is lost transArchive_201301_201303_inactive.\n",
      "Looking at transArchive_201304_201306\n",
      "She swiped right, we have a MATCH! transArchive_201304_201306\n",
      "She blocked us, all hope is lost transArchive_201304_201306.\n",
      "Looking at transArchive_201304_201306_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201304_201306_inactive\n",
      "She blocked us, all hope is lost transArchive_201304_201306_inactive.\n",
      "Looking at transArchive_201307_201309\n",
      "She swiped right, we have a MATCH! transArchive_201307_201309\n",
      "She blocked us, all hope is lost transArchive_201307_201309.\n",
      "Looking at transArchive_201307_201309_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201307_201309_inactive\n",
      "She blocked us, all hope is lost transArchive_201307_201309_inactive.\n",
      "Looking at transArchive_201310_201312\n",
      "She swiped right, we have a MATCH! transArchive_201310_201312\n",
      "She blocked us, all hope is lost transArchive_201310_201312.\n",
      "Looking at transArchive_201310_201312_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201310_201312_inactive\n",
      "She blocked us, all hope is lost transArchive_201310_201312_inactive.\n",
      "Looking at transArchive_201401_201403\n",
      "She swiped right, we have a MATCH! transArchive_201401_201403\n",
      "She blocked us, all hope is lost transArchive_201401_201403.\n",
      "Looking at transArchive_201401_201403_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201401_201403_inactive\n",
      "She blocked us, all hope is lost transArchive_201401_201403_inactive.\n",
      "Looking at transArchive_201404_201406\n",
      "She swiped right, we have a MATCH! transArchive_201404_201406\n",
      "She blocked us, all hope is lost transArchive_201404_201406.\n",
      "Looking at transArchive_201404_201406_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201404_201406_inactive\n",
      "She blocked us, all hope is lost transArchive_201404_201406_inactive.\n",
      "Looking at transArchive_201407_201409\n",
      "She swiped right, we have a MATCH! transArchive_201407_201409\n",
      "She blocked us, all hope is lost transArchive_201407_201409.\n",
      "Looking at transArchive_201407_201409_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201407_201409_inactive\n",
      "She blocked us, all hope is lost transArchive_201407_201409_inactive.\n",
      "Looking at transArchive_201410_201412\n",
      "She swiped right, we have a MATCH! transArchive_201410_201412\n",
      "She blocked us, all hope is lost transArchive_201410_201412.\n",
      "Looking at transArchive_201410_201412_inactive\n",
      "She swiped right, we have a MATCH! transArchive_201410_201412_inactive\n",
      "She blocked us, all hope is lost transArchive_201410_201412_inactive.\n",
      "Looking at transArchive_201501_201503\n",
      "She swiped right, we have a MATCH! transArchive_201501_201503\n",
      "She blocked us, all hope is lost transArchive_201501_201503.\n",
      "Looking at transArchive_201504_201506\n",
      "She swiped right, we have a MATCH! transArchive_201504_201506\n",
      "She blocked us, all hope is lost transArchive_201504_201506.\n",
      "Looking at transArchive_201507_201509\n",
      "She swiped right, we have a MATCH! transArchive_201507_201509\n",
      "She blocked us, all hope is lost transArchive_201507_201509.\n",
      "Looking at transArchive_201510\n",
      "She swiped right, we have a MATCH! transArchive_201510\n",
      "She blocked us, all hope is lost transArchive_201510.\n",
      "Looking at transArchive_201511\n",
      "She swiped right, we have a MATCH! transArchive_201511\n",
      "She blocked us, all hope is lost transArchive_201511.\n",
      "Looking at transArchive_201512\n",
      "She swiped right, we have a MATCH! transArchive_201512\n",
      "She blocked us, all hope is lost transArchive_201512.\n",
      "Looking at transArchive_201601\n",
      "She swiped right, we have a MATCH! transArchive_201601\n",
      "She blocked us, all hope is lost transArchive_201601.\n",
      "Looking at transArchive_201602\n",
      "She swiped right, we have a MATCH! transArchive_201602\n",
      "She blocked us, all hope is lost transArchive_201602.\n",
      "Looking at transArchive_201603\n",
      "She swiped right, we have a MATCH! transArchive_201603\n",
      "She blocked us, all hope is lost transArchive_201603.\n",
      "Looking at transArchive_201604\n",
      "She swiped right, we have a MATCH! transArchive_201604\n",
      "She blocked us, all hope is lost transArchive_201604.\n",
      "Looking at transArchive_201605\n",
      "She swiped right, we have a MATCH! transArchive_201605\n",
      "She blocked us, all hope is lost transArchive_201605.\n",
      "Looking at transArchive_201606\n",
      "She swiped right, we have a MATCH! transArchive_201606\n",
      "She blocked us, all hope is lost transArchive_201606.\n",
      "Looking at transArchive_201607\n",
      "She swiped right, we have a MATCH! transArchive_201607\n",
      "She blocked us, all hope is lost transArchive_201607.\n",
      "Looking at transArchive_201608\n",
      "She swiped right, we have a MATCH! transArchive_201608\n",
      "She blocked us, all hope is lost transArchive_201608.\n",
      "Looking at transArchive_201609\n",
      "She swiped right, we have a MATCH! transArchive_201609\n",
      "She blocked us, all hope is lost transArchive_201609.\n",
      "Looking at transArchive_201610\n",
      "She swiped right, we have a MATCH! transArchive_201610\n",
      "She blocked us, all hope is lost transArchive_201610.\n",
      "Looking at transArchive_201611\n",
      "She swiped right, we have a MATCH! transArchive_201611\n",
      "She blocked us, all hope is lost transArchive_201611.\n",
      "Looking at transArchive_201612\n",
      "She swiped right, we have a MATCH! transArchive_201612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She blocked us, all hope is lost transArchive_201612.\n",
      "Looking at transArchive_201701\n",
      "She swiped right, we have a MATCH! transArchive_201701\n",
      "She blocked us, all hope is lost transArchive_201701.\n"
     ]
    }
   ],
   "source": [
    "# create a regex that matches our table pattern\n",
    "# ymd_pattern = re.compile(r\"^dram_items_[1-2][9,0][1-2][9,0,1,2][01][0-9][01][0-9]$\") \n",
    "\n",
    "transArchive_pattern = re.compile(r\"^transArchive_*\") \n",
    "\n",
    "tables = client.list_tables(dataset_id)  \n",
    "\n",
    "for table in tables:\n",
    "    \n",
    "    print(f'Looking at {table.table_id}')\n",
    "\n",
    "    # Test to see if table.table_id matches the pattern\n",
    "    # if so, delete it\n",
    "    if transArchive_pattern.match(table.table_id):\n",
    "        # print(table.table_id)\n",
    "        print(f'She swiped right, we have a MATCH! {table.table_id}')\n",
    "        # table_id = \".\".join([gbq_proj_id,dataset_id,table.table_id])\n",
    "        # Disabling to prevent accidently running\n",
    "        client.delete_table(table, not_found_ok=True)\n",
    "        print(f\"She blocked us, all hope is lost {table.table_id}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843fc9f",
   "metadata": {},
   "source": [
    "## Uploading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798a6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71b741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78476951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce9952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54cf7b83",
   "metadata": {},
   "source": [
    "# Cleanup ALL Local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a722695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Cleanup\n",
      "Completed Exit Code 0\n"
     ]
    }
   ],
   "source": [
    "# https://linuxize.com/post/python-delete-files-and-directories/\n",
    "try:\n",
    "    # shutil.rmtree(working_directory)\n",
    "    print('Done Cleanup')\n",
    "    print(\"Completed Exit Code 0\")\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (working_directory, e.strerror))\n",
    "    print(\"Completed Exit Code -1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
